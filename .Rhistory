library(devtools)
library(roxygen2)
document()
library(RTSA)
?metaPrepare
perioOxy <- data.frame(trial = c("Greif", "Pryor", "Belda", "Mayzler",
"ENIGMA", "Gardelle", "PROXI"),
year = c(2000,2004,2005,2005,2007,2008,2008),
eI = c(13, 20, 22, 2, 77, 17, 130),
nI = c(250, 80, 148, 19, 997, 69, 694),
eC = c(28, 9, 35, 3, 106, 10, 141),
nC = c(250, 80, 143, 19, 1015, 74, 706))
save(perioOxy, "data/perioOxy.RData")
save(perioOxy, file = "data/perioOxy.RData")
document()
dim(perioOxy)
View(perioOxy)
names(perioOxy)
document()
document()
document
document()
document()
document()
document()
document()
document()
library(RTSA)
data("perioOxy")
perioOxy
with(perioOxy, metaPrepare(outcome = "RR", eI = eI, nI = nI, eC = eC, nC = nC,
method = "MH")
)
document()
data("perioOxy")
m.prepare = with(perioOxy, metaPrepare(outcome = "RR", eI = eI, nI = nI, eC = eC, nC = nC, method = "MH"))
synthesize(m.prepare)
#' \item{peR}{Vector containing random-effects model results - pooled effect size, lower 95% confidence limit, upper 95% confidence limit, z-value (DL) or t-value (HKSJ), p-value, variance of estimate}
#' \item{Q}{vector containing Q-measure, degrees of freedom (df) and p-value for Q}
#' \item{}{vector containing tau2 (random effect variance estimate), H-measure, I2 (inconsistency) and D2 (diversity)}
#'
#' @export
#'
#' @examples
#' data(perioOxy)
#' m.prepare = with(perioOxy, metaPrepare(outcome = "RR", eI = eI, nI = nI, eC = eC, nC = nC, method = "MH"))
#' synthesize(m.prepare)
synthesize <- function(y, sign = NULL, random = TRUE, fixedStudy = TRUE, hakn = FALSE){
# returns:
#   fw: vector containing the weights in the fixed effects model
#   peF: vector containing fixed effects model results - pooled effect size, confidence interval, z.value
#        p-value
#   rwR: vector containing the weights in the random effects model
#   peR: vector containing random effects model results - pooled effect size, confidence interval, z.value
#        p-value
#   Q: vector containing: Q-meaure, degrees of freedom (df) and p-value for Q
#   U: vector containing: tau2 (random effect variance estimate), H-measure and I2 (heterogenity).
if(class(y) != "synthPrepped"){
warning('sig object is not of synthPrepped-class, results may be inaccurate')
}
w <- y$w   # collect objects
sig <- y$sig
te <- y$te
pe <- y$pe
eI <- y$eI
eC <- y$eC
nI <- y$nI
nC <- y$nC
df <- length(w)-1
if(length(w) == 1) df <- 1 #check up on this
if(y$method == "GLM"){
bi <- nI - eI
di <- nC - eC
grpOut <- cbind(xi = c(rbind(eI, eC)), mi = c(rbind(bi, di)))
k <- length(eI)
eff <- rep(rep(1,k),2)
trial <- factor(rep(seq_len(k), each = 2))
group <- rep(c(1,0), times = k)
eff <- eff*group
if(fixedStudy == FALSE){
const <- rep(rep(1,k),2)
glmFit <- glmer(grpOut ~ -1 + eff + const +(1| trial),
nAGQ = 7, family = binomial)
es <- glmFit@beta[1]
sigma2 <- lme4::VarCorr(glmFit)[[1]][1]
tau2 <- 0
} else {
glmFit <- glm(grpOut ~ -1 + eff + trial, family = binomial)
es <- coef(glmFit)[1]
}
se <- sqrt(vcov(glmFit)[1,1])
zval <- es/se
pval <- 2*pnorm(abs(zval), lower.tail = FALSE)
lci <- exp(es - qnorm(0.05/2, lower.tail = FALSE)*se)
uci <- exp(es + qnorm(0.05/2, lower.tail = FALSE)*se)
fpe <- exp(es)
if(random == TRUE){
sv <- rep(c(.5,-.5), times = k)
if(fixedStudy == FALSE){
glmRandomFit <- glmer(grpOut ~ -1 + eff + const + (1|trial) +
(sv-1|trial), family = binomial)
} else {
glmRandomFit <- glmer(grpOut ~ -1 + eff + trial + (sv-1|trial), family = binomial,
nAGQ = 7)
}
esR <- glmRandomFit@beta[1]
seR <- sqrt(vcov(glmRandomFit)[1,1])
if(fixedStudy == TRUE){
tau2 <- VarCorr(glmRandomFit)[[1]][1]
} else {
tau2 <- VarCorr(glmRandomFit)[[2]][1]
sigma2 <- VarCorr(glmRandomFit)[[1]][1]
}
zvalR <- esR/seR
pvalR <- 2*pnorm(abs(zvalR), lower.tail = FALSE)
lciR <- exp(esR - qnorm(0.05/2, lower.tail = FALSE)*seR)
uciR <- exp(esR + qnorm(0.05/2, lower.tail = FALSE)*seR)
peR <- exp(esR)
return(list(peF = c(fpe,lci,uci, zval, pval, se, es), peR = c(peR, lciR, uciR, zvalR, pvalR),
U = tau2))
} else { # GLM and NOT RANDOM
return(peF = c(fpe,lci,uci, zval, pval, se, es))
}} else { # NOT GLM
if(y$method != "MH") w <- 1/(sig^2) # weight inverse variance
rw <- w/sum(w) # relative weight
vw <- 1/sum(w) # variance of pooled effect
if(y$method == "cont"){
peF <- sum(w*te)/sum(w)
lci <- peF - 1.96*sqrt(vw)
uci <- peF + 1.96*sqrt(vw)
if(is.null(sign)) {zval <- peF/sqrt(vw)
} else {
zval <- sign*peF/sqrt(vw)
}
pval <- (1-pnorm(abs(zval)))*2
} else if(y$method == "MH"){ # method the same for OR and RR
vw <- pe[2]
lpeF <- log(sum(te*w)/sum(w))
lci <- exp(lpeF - 1.96*sqrt(vw))
uci <- exp(lpeF + 1.96*sqrt(vw))
peF <- exp(lpeF)
if(is.null(sign)) {zval <- lpeF/sqrt(vw)
} else {
zval <- sign*lpeF/sqrt(vw)
}
pval <- (1-pnorm(abs(zval)))* 2
} else {
lpeF <- sum(log(te)*rw) # fixed effect log pooled estimate
uci <- exp(lpeF+1.96*sqrt(vw))
lci <- exp(lpeF-1.96*sqrt(vw))
peF <- exp(lpeF)
if(is.null(sign)) {zval <- lpeF/sqrt(vw)
} else {
zval <- sign*lpeF/sqrt(vw)
}
pval <- (1-pnorm(abs(zval)))* 2
}
if(y$method != "cont"){
w <- 1/(sig^2)
Q <- sum(w*log(te)^2)-(sum(w*log(te)))^2/sum(w)
U <- sum(w)-sum(w^2)/sum(w)
tau2 <- ifelse(Q > df, (Q-df)/U, 0) # DerSimonian-Laird estimate
pQ <- pchisq(Q, df, lower.tail = FALSE)
if(!is.na(Q) & Q/df <= 0) {
H <- 0
} else if(is.na(Q)){
H <- NA
} else {
H <- sqrt(Q/df)
}
I2 <- ifelse((Q-df)/Q >= 0, (Q-df)/Q, 0)
# random effect
if(random == TRUE){ # cal. random effect weights and belonging pooled estimate
wR <- 1/(sig^2+tau2)
vwR <- 1/sum(wR) # variance of pooled effect (random)
rwR <- wR*vwR
teR <- sum(te*wR)/sum(wR)
leR <- sum(log(te)*rwR)
peR <- exp(leR)
if(hakn == TRUE){
vwR <- 1/df * sum(wR * (log(te) - leR)^2/sum(wR))
if(is.null(sign)) {zvalR <- leR/sqrt(vwR)
} else {
zvalR <- sign*leR/sqrt(vwR)
}
pvalR <- 2*pt(abs(zvalR), df = df, lower.tail = FALSE)
lciR <- exp(leR-qt(1-0.05/2, df = df)*sqrt(vwR))
uciR <- exp(leR+qt(1-0.05/2, df = df)*sqrt(vwR))
} else {
if(is.null(sign)) {zvalR <- leR/sqrt(vwR)
} else {
zvalR <- sign*leR/sqrt(vwR)
}
pvalR <- (1-pnorm(abs(zvalR)))* 2
lciR <- exp(leR-1.96*sqrt(vwR))
uciR <- exp(leR+1.96*sqrt(vwR)) }
vw <- 1/sum(w)
D2 <- 1-vw/vwR
synth <- list(fw = round(rw*100,1), peF = c(peF,lci,uci, zval, pval, lpeF, vw),
rwR = rwR*100, peR = c(peR, lciR, uciR, zvalR, pvalR, vwR),
Q = c(Q,df,pQ), U = c(tau2,H, I2, D2))
class(synth) <- "synthesized"
return(synth)
} else {
synth <- list(peF = c(peF, lci, uci, zval, pval, lpeF, vw), Q = c(Q,df,pQ), U = c(tau2,H, I2))
class(synth) <- "synthesized"
return(synth) }
} else {
Q <- sum(w*te^2)-(sum(w*te))^2/sum(w)
U <- sum(w)-sum(w^2)/sum(w)
tau2 <- ifelse(Q > df, (Q-df)/U, 0)
wR <- 1/(sig^2+tau2)
vwR <- 1/sum(wR) # variance of pooled effect (random)
rwR <- wR*vwR
peRest <- sum(te*wR)/sum(wR)
lciR <- peRest - 1.96*sqrt(vwR)
uciR <- peRest + 1.96*sqrt(vwR)
zvalR <- peRest/sqrt(vwR)
pvalR <- 2*(1-pnorm(abs(zvalR)))
pQ <- pchisq(Q, df, lower.tail = FALSE)
H <- sqrt(Q/df)
I2 <- (Q-df)/Q
D2 <- (1 - vw/vwR)
synth <- list(fw = round(w/sum(w)*100,1), peF = c(peF, vw, lci, uci, zval, pval),
w = w,
rwR = round(rwR*100,1),
peR = c(peRest, vwR, lciR, uciR, zvalR, pvalR),
Q = c(Q, df, pQ),
U = c(tau2, H, I2, D2))
class(synth) <- "synthesized"
return(synth)
}
}}
synthesize(m.prepare)
document()
rm(list = ls())
document()
document()
document()
?glmer
?VarCorr
document()
?vcov
document()
document()
document()
document()
document()
document()
document()
document()
document()
# Read libraries and Source functions  ------------------------------------
# source functions
source("~/Documents/PhD/TSA/code/TSAjava/ProcLanDeMets.R")
# Data clean and preparation ----------------------------------------------
# read the data
count <- c(500, 160, 148+143, 19+19, 997+1015, 69+74, 694+706)
timing <- c(cumsum(count)/7224,1)
# create incr in information
timingincr <- timing - c(0,timing[-length(timing)])
trials <- cbind(timing, timingincr)
# select trials
trials <- trials[c(1,3,4,5,7,8),]
# Start BoundaryCalculations programme ------------------------------------
# set thresholds:
IFincrementThreshold <- 0.01
IFtotalThreshold <- 0.05
trials <- trials[trials[,2] > IFincrementThreshold,]
# (newgraph - getInnerWedgeGraph)
boundaries <- standardBoundary(informationFractions = trials[-1,1],
side = 2, alpha = 0.05, zninf = -8, tol = 1e-13)
boundaries
fakeIFY <- boundaries$ret2[length(boundaries$ret2)]
innerboundaries <- getInnerWedge(informationFractions = trials[-1,1], beta = 0.2,
delta = 0, side = 1, fakeIFY = fakeIFY, zninf = -8, tol = 1e-13)
innerboundaries$ret2
# compare to other
library(gsDesign)
plot(gsDesign(k = 5, timing = c(0.06921373, 0.13164452, 0.41542082, 0.62901440, 1), test.type = 4,
alpha = 0.025, beta = 0.2, sfu = sfLDOF, sfl = sfLDOF))
standardBoundary(informationFractions = c(0.06921373, 0.13164452, 0.41542082, 0.62901440, 1),
side = 2, alpha = 0.05, zninf = -8, tol = 1e-9)
boundaries <- standardBoundary(informationFractions = c(0.13164452, 0.41542082, 0.62901440,1),
side = 2, alpha = 0.05, zninf = -8, tol = 1e-9)
fakeIFY <- boundaries$ret2[length(boundaries$ret2)]
innerboundaries <- getInnerWedge(informationFractions = c(0.13164452, 0.41542082, 0.62901440,1), beta = 0.2,
delta = 0, side = 1, fakeIFY = fakeIFY, zninf = -2.9, tol = 1e-13)
innerboundaries$ret2
