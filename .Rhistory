with(perioOxy, metaPrepare(outcome = "RR", eI = eI, nI = nI, eC = eC, nC = nC,
method = "MH")
)
document()
data("perioOxy")
m.prepare = with(perioOxy, metaPrepare(outcome = "RR", eI = eI, nI = nI, eC = eC, nC = nC, method = "MH"))
synthesize(m.prepare)
#' \item{peR}{Vector containing random-effects model results - pooled effect size, lower 95% confidence limit, upper 95% confidence limit, z-value (DL) or t-value (HKSJ), p-value, variance of estimate}
#' \item{Q}{vector containing Q-measure, degrees of freedom (df) and p-value for Q}
#' \item{}{vector containing tau2 (random effect variance estimate), H-measure, I2 (inconsistency) and D2 (diversity)}
#'
#' @export
#'
#' @examples
#' data(perioOxy)
#' m.prepare = with(perioOxy, metaPrepare(outcome = "RR", eI = eI, nI = nI, eC = eC, nC = nC, method = "MH"))
#' synthesize(m.prepare)
synthesize <- function(y, sign = NULL, random = TRUE, fixedStudy = TRUE, hakn = FALSE){
# returns:
#   fw: vector containing the weights in the fixed effects model
#   peF: vector containing fixed effects model results - pooled effect size, confidence interval, z.value
#        p-value
#   rwR: vector containing the weights in the random effects model
#   peR: vector containing random effects model results - pooled effect size, confidence interval, z.value
#        p-value
#   Q: vector containing: Q-meaure, degrees of freedom (df) and p-value for Q
#   U: vector containing: tau2 (random effect variance estimate), H-measure and I2 (heterogenity).
if(class(y) != "synthPrepped"){
warning('sig object is not of synthPrepped-class, results may be inaccurate')
}
w <- y$w   # collect objects
sig <- y$sig
te <- y$te
pe <- y$pe
eI <- y$eI
eC <- y$eC
nI <- y$nI
nC <- y$nC
df <- length(w)-1
if(length(w) == 1) df <- 1 #check up on this
if(y$method == "GLM"){
bi <- nI - eI
di <- nC - eC
grpOut <- cbind(xi = c(rbind(eI, eC)), mi = c(rbind(bi, di)))
k <- length(eI)
eff <- rep(rep(1,k),2)
trial <- factor(rep(seq_len(k), each = 2))
group <- rep(c(1,0), times = k)
eff <- eff*group
if(fixedStudy == FALSE){
const <- rep(rep(1,k),2)
glmFit <- glmer(grpOut ~ -1 + eff + const +(1| trial),
nAGQ = 7, family = binomial)
es <- glmFit@beta[1]
sigma2 <- lme4::VarCorr(glmFit)[[1]][1]
tau2 <- 0
} else {
glmFit <- glm(grpOut ~ -1 + eff + trial, family = binomial)
es <- coef(glmFit)[1]
}
se <- sqrt(vcov(glmFit)[1,1])
zval <- es/se
pval <- 2*pnorm(abs(zval), lower.tail = FALSE)
lci <- exp(es - qnorm(0.05/2, lower.tail = FALSE)*se)
uci <- exp(es + qnorm(0.05/2, lower.tail = FALSE)*se)
fpe <- exp(es)
if(random == TRUE){
sv <- rep(c(.5,-.5), times = k)
if(fixedStudy == FALSE){
glmRandomFit <- glmer(grpOut ~ -1 + eff + const + (1|trial) +
(sv-1|trial), family = binomial)
} else {
glmRandomFit <- glmer(grpOut ~ -1 + eff + trial + (sv-1|trial), family = binomial,
nAGQ = 7)
}
esR <- glmRandomFit@beta[1]
seR <- sqrt(vcov(glmRandomFit)[1,1])
if(fixedStudy == TRUE){
tau2 <- VarCorr(glmRandomFit)[[1]][1]
} else {
tau2 <- VarCorr(glmRandomFit)[[2]][1]
sigma2 <- VarCorr(glmRandomFit)[[1]][1]
}
zvalR <- esR/seR
pvalR <- 2*pnorm(abs(zvalR), lower.tail = FALSE)
lciR <- exp(esR - qnorm(0.05/2, lower.tail = FALSE)*seR)
uciR <- exp(esR + qnorm(0.05/2, lower.tail = FALSE)*seR)
peR <- exp(esR)
return(list(peF = c(fpe,lci,uci, zval, pval, se, es), peR = c(peR, lciR, uciR, zvalR, pvalR),
U = tau2))
} else { # GLM and NOT RANDOM
return(peF = c(fpe,lci,uci, zval, pval, se, es))
}} else { # NOT GLM
if(y$method != "MH") w <- 1/(sig^2) # weight inverse variance
rw <- w/sum(w) # relative weight
vw <- 1/sum(w) # variance of pooled effect
if(y$method == "cont"){
peF <- sum(w*te)/sum(w)
lci <- peF - 1.96*sqrt(vw)
uci <- peF + 1.96*sqrt(vw)
if(is.null(sign)) {zval <- peF/sqrt(vw)
} else {
zval <- sign*peF/sqrt(vw)
}
pval <- (1-pnorm(abs(zval)))*2
} else if(y$method == "MH"){ # method the same for OR and RR
vw <- pe[2]
lpeF <- log(sum(te*w)/sum(w))
lci <- exp(lpeF - 1.96*sqrt(vw))
uci <- exp(lpeF + 1.96*sqrt(vw))
peF <- exp(lpeF)
if(is.null(sign)) {zval <- lpeF/sqrt(vw)
} else {
zval <- sign*lpeF/sqrt(vw)
}
pval <- (1-pnorm(abs(zval)))* 2
} else {
lpeF <- sum(log(te)*rw) # fixed effect log pooled estimate
uci <- exp(lpeF+1.96*sqrt(vw))
lci <- exp(lpeF-1.96*sqrt(vw))
peF <- exp(lpeF)
if(is.null(sign)) {zval <- lpeF/sqrt(vw)
} else {
zval <- sign*lpeF/sqrt(vw)
}
pval <- (1-pnorm(abs(zval)))* 2
}
if(y$method != "cont"){
w <- 1/(sig^2)
Q <- sum(w*log(te)^2)-(sum(w*log(te)))^2/sum(w)
U <- sum(w)-sum(w^2)/sum(w)
tau2 <- ifelse(Q > df, (Q-df)/U, 0) # DerSimonian-Laird estimate
pQ <- pchisq(Q, df, lower.tail = FALSE)
if(!is.na(Q) & Q/df <= 0) {
H <- 0
} else if(is.na(Q)){
H <- NA
} else {
H <- sqrt(Q/df)
}
I2 <- ifelse((Q-df)/Q >= 0, (Q-df)/Q, 0)
# random effect
if(random == TRUE){ # cal. random effect weights and belonging pooled estimate
wR <- 1/(sig^2+tau2)
vwR <- 1/sum(wR) # variance of pooled effect (random)
rwR <- wR*vwR
teR <- sum(te*wR)/sum(wR)
leR <- sum(log(te)*rwR)
peR <- exp(leR)
if(hakn == TRUE){
vwR <- 1/df * sum(wR * (log(te) - leR)^2/sum(wR))
if(is.null(sign)) {zvalR <- leR/sqrt(vwR)
} else {
zvalR <- sign*leR/sqrt(vwR)
}
pvalR <- 2*pt(abs(zvalR), df = df, lower.tail = FALSE)
lciR <- exp(leR-qt(1-0.05/2, df = df)*sqrt(vwR))
uciR <- exp(leR+qt(1-0.05/2, df = df)*sqrt(vwR))
} else {
if(is.null(sign)) {zvalR <- leR/sqrt(vwR)
} else {
zvalR <- sign*leR/sqrt(vwR)
}
pvalR <- (1-pnorm(abs(zvalR)))* 2
lciR <- exp(leR-1.96*sqrt(vwR))
uciR <- exp(leR+1.96*sqrt(vwR)) }
vw <- 1/sum(w)
D2 <- 1-vw/vwR
synth <- list(fw = round(rw*100,1), peF = c(peF,lci,uci, zval, pval, lpeF, vw),
rwR = rwR*100, peR = c(peR, lciR, uciR, zvalR, pvalR, vwR),
Q = c(Q,df,pQ), U = c(tau2,H, I2, D2))
class(synth) <- "synthesized"
return(synth)
} else {
synth <- list(peF = c(peF, lci, uci, zval, pval, lpeF, vw), Q = c(Q,df,pQ), U = c(tau2,H, I2))
class(synth) <- "synthesized"
return(synth) }
} else {
Q <- sum(w*te^2)-(sum(w*te))^2/sum(w)
U <- sum(w)-sum(w^2)/sum(w)
tau2 <- ifelse(Q > df, (Q-df)/U, 0)
wR <- 1/(sig^2+tau2)
vwR <- 1/sum(wR) # variance of pooled effect (random)
rwR <- wR*vwR
peRest <- sum(te*wR)/sum(wR)
lciR <- peRest - 1.96*sqrt(vwR)
uciR <- peRest + 1.96*sqrt(vwR)
zvalR <- peRest/sqrt(vwR)
pvalR <- 2*(1-pnorm(abs(zvalR)))
pQ <- pchisq(Q, df, lower.tail = FALSE)
H <- sqrt(Q/df)
I2 <- (Q-df)/Q
D2 <- (1 - vw/vwR)
synth <- list(fw = round(w/sum(w)*100,1), peF = c(peF, vw, lci, uci, zval, pval),
w = w,
rwR = round(rwR*100,1),
peR = c(peRest, vwR, lciR, uciR, zvalR, pvalR),
Q = c(Q, df, pQ),
U = c(tau2, H, I2, D2))
class(synth) <- "synthesized"
return(synth)
}
}}
synthesize(m.prepare)
document()
rm(list = ls())
document()
document()
document()
?glmer
?VarCorr
document()
?vcov
document()
document()
document()
document()
document()
document()
document()
document()
document()
# Read libraries and Source functions  ------------------------------------
# source functions
source("~/Documents/PhD/TSA/code/TSAjava/ProcLanDeMets.R")
# Data clean and preparation ----------------------------------------------
# read the data
count <- c(500, 160, 148+143, 19+19, 997+1015, 69+74, 694+706)
timing <- c(cumsum(count)/7224,1)
# create incr in information
timingincr <- timing - c(0,timing[-length(timing)])
trials <- cbind(timing, timingincr)
# select trials
trials <- trials[c(1,3,4,5,7,8),]
# Start BoundaryCalculations programme ------------------------------------
# set thresholds:
IFincrementThreshold <- 0.01
IFtotalThreshold <- 0.05
trials <- trials[trials[,2] > IFincrementThreshold,]
# (newgraph - getInnerWedgeGraph)
boundaries <- standardBoundary(informationFractions = trials[-1,1],
side = 2, alpha = 0.05, zninf = -8, tol = 1e-13)
boundaries
fakeIFY <- boundaries$ret2[length(boundaries$ret2)]
innerboundaries <- getInnerWedge(informationFractions = trials[-1,1], beta = 0.2,
delta = 0, side = 1, fakeIFY = fakeIFY, zninf = -8, tol = 1e-13)
innerboundaries$ret2
# compare to other
library(gsDesign)
plot(gsDesign(k = 5, timing = c(0.06921373, 0.13164452, 0.41542082, 0.62901440, 1), test.type = 4,
alpha = 0.025, beta = 0.2, sfu = sfLDOF, sfl = sfLDOF))
standardBoundary(informationFractions = c(0.06921373, 0.13164452, 0.41542082, 0.62901440, 1),
side = 2, alpha = 0.05, zninf = -8, tol = 1e-9)
boundaries <- standardBoundary(informationFractions = c(0.13164452, 0.41542082, 0.62901440,1),
side = 2, alpha = 0.05, zninf = -8, tol = 1e-9)
fakeIFY <- boundaries$ret2[length(boundaries$ret2)]
innerboundaries <- getInnerWedge(informationFractions = c(0.13164452, 0.41542082, 0.62901440,1), beta = 0.2,
delta = 0, side = 1, fakeIFY = fakeIFY, zninf = -2.9, tol = 1e-13)
innerboundaries$ret2
library(RTSA)
library(RTSA)
library(usethis)
usethis::use_vignette("other-software")
library(RTSA)
library(gsDesign)
data("perioOxy")
usethis::use_vignette("required-sample-size")
library(RTSA)
library(ggplot2)
trials = 37
ceiling(2*var.k/(log.RR^2*trials/((qnorm(1-alpha/2)+qnorm(1-beta))^2)-tau2))
# we start with a fixed effect model
outl = matrix(NA, ncol = 3, nrow = 10)
for(l in 1:10){
RR <- 0.9
p0 <- 0.1
pI <- round(exp(log(p0)+log(RR)/2),4)
pC <- round(exp(log(p0)-log(RR)/2),4)
theta = round(pC - pI,4)
n = ceiling(l/10*4*(qnorm(1-0.05/2)+qnorm(1-0.2))^2*(p0*(1-p0))/theta^2/10/2)
K = 10
nsim = 10000
outpvalue = matrix(NA, ncol = 3, nrow = nsim)
for(h in 1:nsim){
outmat = matrix(NA, ncol = 9, nrow = K)
zvalues = NULL
for(i in 1:K){
eA <- apply(cbind(n, pI), 1,
function(x) rbinom(1, size = x[1], prob = x[2]))
eB <- apply(cbind(n, pC), 1,
function(x) rbinom(1, size = x[1], prob = x[2]))
outmat[i,1:4] = c(eA, n, eB, n)
}
synout = metaPrepare(outcome = "RR", eI = outmat[,1], nI = outmat[,2],
eC = outmat[,3], nC = outmat[,2],
method = "MH")
out1 = synthesize(synout, hakn = FALSE)
out2 = synthesize(synout, hakn = TRUE)
outpvalue[h, c(1,2,3)] = c(round(out1$peF[5],4), round(out1$peR[5],4), out2$peR[5])
}
outl[l,1] = sum(outpvalue[,1] < 0.05)/nsim
outl[l,2] = sum(outpvalue[,2] < 0.05)/nsim
outl[l,3] = sum(outpvalue[,3] < 0.05)/nsim
}
x1 = ceiling(c(1:10)/10*4*(qnorm(1-0.05/2)+qnorm(1-0.2))^2*(p0*(1-p0))/theta^2)
dat1 = data.frame(outl, x1)
library(reshape2)
dat2 = melt(dat1,id.vars = c("x1"))
dat2$method = rep(c("Fixed-effect", "Random-effects - DL", "Random-effects - HKSJ"), each = 10)
ggplot(data=dat2, aes(x=x1, y=value, group = method, color = method)) +
geom_hline(yintercept = 0.8, col = "gray", cex = 1.5)  +
geom_line()+ scale_y_continuous(labels = scales::percent) +
scale_x_continuous(labels = scales::comma)  +
labs(x = "Total number of participants", y = "Power")+
geom_point() +
theme_bw() + theme(legend.position="bottom") +
scale_color_brewer(palette="Set1")
library(grid)
\
library(tiff)
library(RTSA)
library(RTSA)
library(RTSA)
?minTrial
help(RTSA::minTrial)
help(RTSA)
library(RTSA)
?metaPrepare
usethis::document()
document()
library(devtools)
document()
library(RTSA)
?minTrial
library(RTSA)
library(grid)
library(tiff)
minTrial(metric = "RR", value = 0.9, tau2 = 0.05, p0 = 0.1, verbose = TRUE)
minTrial(metric = "RR", value = 0.9, tau2 = 0.05, p0 = 0.1, verbose = TRUE)
trial.out = minTrial(metric = "RR", value = 0.9, tau2 = 0.05, p0 = 0.1, verbose = TRUE)
1:dim(trial.out$nPax)[2]
RR <- 0.9
p0 <- 0.1
pI <- round(exp(log(p0)+log(RR)/2),4)
pC <- round(exp(log(p0)-log(RR)/2),4)
theta = round(pC - pI,4)
nsim = 10000
tau2 = 0.05
trial.out = minTrial(metric = "RR", value = 0.9, tau2 = 0.05, p0 = 0.1, verbose = TRUE)
K = trial.out$nPax[1,l]
n = trial.out$nPax[2,l]
l = 1
K = trial.out$nPax[1,l]
n = trial.out$nPax[2,l]
K
n
#outmat = matrix(NA, ncol = 9, nrow = K*10)
#zvalues = NULL
ln_RR = rnorm(K, mean = log(RR), sd = sqrt(tau2))
ln_RR
pI = exp(log(p0)+ln_RR/2)
pI[pI < 0.01] = 0.01
pI[pI > 0.99] = 0.99
pC = exp(log(p0)-ln_RR/2)
pC[pC < 0.01] = 0.01
pC[pC > 0.99] = 0.99
for(i in 1:(K)){
eA <- apply(cbind(n/2, pI[i]), 1,
function(x) rbinom(1, size = x[1], prob = x[2]))
eB <- apply(cbind(n/2, pC[i]), 1,
function(x) rbinom(1, size = x[1], prob = x[2]))
outmat[i,1:4] = c(eA, n, eB, n)
}
outmat = matrix(NA,ncol = 4, nrow = K)
for(i in 1:(K)){
eA <- apply(cbind(n/2, pI[i]), 1,
function(x) rbinom(1, size = x[1], prob = x[2]))
eB <- apply(cbind(n/2, pC[i]), 1,
function(x) rbinom(1, size = x[1], prob = x[2]))
outmat[i,1:4] = c(eA, n/2, eB, n/2)
}
outmat
n/2
for(i in 1:(K)){
eA <- apply(cbind(ceiling(n/2), pI[i]), 1,
function(x) rbinom(1, size = x[1], prob = x[2]))
eB <- apply(cbind(ceiling(n/2), pC[i]), 1,
function(x) rbinom(1, size = x[1], prob = x[2]))
outmat[i,1:4] = c(eA, ceiling(n/2), eB, ceiling(n/2))
}
outmat
synout = synthPrepare(outcome = "RR", eI = outmat[,1], nI = outmat[,2],
eC = outmat[,3], nC = outmat[,2],
method = "IV")
synout = metaPrepare(outcome = "RR", eI = outmat[,1], nI = outmat[,2],
eC = outmat[,3], nC = outmat[,2],
method = "IV")
out1 = synthesize(synout, hakn = FALSE)
out2 = synthesize(synout, hakn = TRUE)
outpvalue = matrix(NA, ncol = 3, nrow = nsim)
h = 1
outpvalue[h, c(1,2,3)] = c(round(out1$peF[5],4), round(out1$peR[5],4), out2$peR[5])
head(outpvalue)
trial.out = minTrial(metric = "RR", value = 0.9, tau2 = 0.05, p0 = 0.1, verbose = TRUE)
outtau = numeric(nsim)
outpvalue = matrix(NA, ncol = 3, nrow = nsim)
K = trial.out$nPax[1,l]
n = trial.out$nPax[2,l]
for(h in 1:nsim){
outmat = matrix(NA,ncol = 4, nrow = K)
#zvalues = NULL
ln_RR = rnorm(K, mean = log(RR), sd = sqrt(tau2))
pI = exp(log(p0)+ln_RR/2)
pI[pI < 0.01] = 0.01
pI[pI > 0.99] = 0.99
pC = exp(log(p0)-ln_RR/2)
pC[pC < 0.01] = 0.01
pC[pC > 0.99] = 0.99
for(i in 1:(K)){
eA <- apply(cbind(ceiling(n/2), pI[i]), 1,
function(x) rbinom(1, size = x[1], prob = x[2]))
eB <- apply(cbind(ceiling(n/2), pC[i]), 1,
function(x) rbinom(1, size = x[1], prob = x[2]))
outmat[i,1:4] = c(eA, ceiling(n/2), eB, ceiling(n/2))
}
synout = metaPrepare(outcome = "RR", eI = outmat[,1], nI = outmat[,2],
eC = outmat[,3], nC = outmat[,2],
method = "IV")
out1 = synthesize(synout, hakn = FALSE)
out2 = synthesize(synout, hakn = TRUE)
outpvalue[h, c(1,2,3)] = c(round(out1$peF[5],4), round(out1$peR[5],4), out2$peR[5])
}
sum(outpvalue[,1] <= 0.05)/nsim
sum(outpvalue[,2] <= 0.05)/nsim
sum(outpvalue[,3] <= 0.05)/nsim
outl = matrix(NA, ncol = 3, nrow = 4)
RR <- 0.9
p0 <- 0.1
pI <- round(exp(log(p0)+log(RR)/2),4)
pC <- round(exp(log(p0)-log(RR)/2),4)
theta = round(pC - pI,4)
nsim = 10000
tau2 = 0.05
trial.out = minTrial(metric = "RR", value = 0.9, tau2 = 0.05, p0 = 0.1, verbose = TRUE)
outtau = numeric(nsim)
outpvalue = matrix(NA, ncol = 3, nrow = nsim)
for(l in 1:dim(trial.out$nPax)[2]){
K = trial.out$nPax[1,l]
n = trial.out$nPax[2,l]
for(h in 1:nsim){
outmat = matrix(NA,ncol = 4, nrow = K)
#zvalues = NULL
ln_RR = rnorm(K, mean = log(RR), sd = sqrt(tau2))
pI = exp(log(p0)+ln_RR/2)
pI[pI < 0.01] = 0.01
pI[pI > 0.99] = 0.99
pC = exp(log(p0)-ln_RR/2)
pC[pC < 0.01] = 0.01
pC[pC > 0.99] = 0.99
for(i in 1:(K)){
eA <- apply(cbind(ceiling(n/2), pI[i]), 1,
function(x) rbinom(1, size = x[1], prob = x[2]))
eB <- apply(cbind(ceiling(n/2), pC[i]), 1,
function(x) rbinom(1, size = x[1], prob = x[2]))
outmat[i,1:4] = c(eA, ceiling(n/2), eB, ceiling(n/2))
}
synout = metaPrepare(outcome = "RR", eI = outmat[,1], nI = outmat[,2],
eC = outmat[,3], nC = outmat[,2],
method = "IV")
out1 = synthesize(synout, hakn = FALSE)
out2 = synthesize(synout, hakn = TRUE)
outpvalue[h, c(1,2,3)] = c(round(out1$peF[5],4), round(out1$peR[5],4), out2$peR[5])
}
outl[l,1] = sum(outpvalue[,1] <= 0.05)/nsim
outl[l,2] = sum(outpvalue[,2] <= 0.05)/nsim
outl[l,3] = sum(outpvalue[,3] <= 0.05)/nsim
}
log.RR = log(0.9); log.p0 = log(0.1)
pI = exp(log.p0+log.RR/2)
pC = exp(log.p0-log.RR/2)
nFixed(alpha = 0.05, beta = 0.2, pI = pI, pC = pC, binary = TRUE)
outl
colnames(outl) = c("Fixed-effect", "Random-effects DL", "Random-effects HKSJ")
outl
rownames(outl) = trial.out$nPax[1,]
outl
rbind(outl, trial.out$nPax[2,])
cbind(outl, trial.out$nPax[2,])
outl = cbind(outl, trial.out$nPax[1,], trial.out$nPax[2,])
colnames(outl) = c("Fixed-effect", "Random-effects DL", "Random-effects HKSJ",
"Number of trials", "Participants per trial")
outl
save("random-effects.Rda")
save("random-effects.Rda", file = outl)
?save
save(outl, file = "random-effects.Rda")
getwd
getwd()
load("random-effects.Rda")
load("random-effects.Rda")
kable(outl)
load("random-effects.Rda")
kntir::kable(outl)
load("random-effects.Rda")
knitr::kable(outl)
rownames(outl) = c("","","","")
save(outl, file = "vignettes/random-effects.Rda")
load("random-effects.Rda")
knitr::kable(outl)
load("random-effects.Rda")
knitr::kable(outl, caption = "Test table")
source("~/Documents/PhD/TSA/code/plotRpackage.R", echo=TRUE)
