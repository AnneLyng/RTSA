---
title: "RTSA-manual"
output: 
  bookdown::html_document2:
    toc: true
    toc_depth: 2
    fig_caption: yes
vignette: >
  %\VignetteIndexEntry{rtsa-manual}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: /home/anne/Documents/PhD/packages/RTSA/phd.bib
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r, include=FALSE}
library(dplyr)
library(kableExtra)
library(RTSA)
```

# Introduction to Trial Sequential Analysis

Trial Sequential Analysis (TSA) is a method for conducting sequential meta-analysis.

The purpose of this document is to function as a working manual for both statisticians and non-statisticians. It will contain descriptions of some of the key methods behind TSA. For more statistical and technical descriptions, we recommend reading the vignettes to this package.

This manual will start with a short introduction to when a sequential meta-analysis should be considered before moving to main section of this manual about the statistical background. The statistical background section will contain a short introduction to hypothesis testing, type I and type II errors, ...

## Why do a sequential meta-analysis

Testing the same hypothesis more than once, using standard meta-analysis methods, as data/studies accumulate sequentially over time is known to inflate the risk of finding false positives. Inflation of finding false positives is also called inflation of the type I error. Hence for a repeated meta-analysis, some findings may have a higher risk of being false compared to the set risk of e.g. 5% usually used in a traditional non-sequential meta-analysis. Sequential meta-analysis controls the risk of finding false positives by using group sequential methods originally created for clinical trials. TSA is an implementation/method of sequential meta-analysis. 

Sequential meta-analysis should be considered, if the intend of the meta-analysis is to produce statistical inference such as p-values to aid in a decision making e.g. regarding modifying general practices or standard of care. If the hypothesis test to aid in the decision making is computed sequentially, hence the meta-analysis is updated at least once, the p-value can no longer be interpreted in the standard manner and must be evaluated from the perspective of the hypothesis being tested multiple times.

It is of interest to control for finding false positives, which can be achieved by using TSA correctly. But, RTSA also provides information about the risk of finding false negatives, known as the type II error. 

# Statistical background

This section will describe some of the statistical terms such as type I and type II errors, $p$-values, $z$-values, $\alpha$ and $\beta$ spending functions and more used to create a trial sequential analysis. It is not recommended to fit TSA without statistical knowledge, but ones knowledge about some of the metrics just described might need to be refreshed. These following subsections are intended for those.

## Hypothesis testing

TSA can be used for correcting the $p$-value, where the p-value is used for making a decision about the likelihood of ones hypothesis. `RTSA` accommodates different types of hypothesis testing including:

1.  Two sided (Two-tailed) testing
2.  One sided (One-tailed) testing
3.  Futility testing

Each of these will be explained below. For all of the different hypothesis tests, we are interested in the distinction between the null hypothesis, often denoted $H_0$, and the alternative hypothesis, often denoted $H_A$. The statistical hypothesis test is, most often, from the perspective of finding evidence against the null hypothesis. Hence we will believe in the null hypothesis until proven otherwise in relation to some probability of the null hypothesis being true, which in TSA, and most other scenarios, is the pre-specified $\alpha$ significance level. A subsection is dedicated to describe the role of $\alpha$. For now we will return to the different form of hypothesis tests available in `RTSA`. 

We will use some mathematical notation when presenting the different types of hypothesis tests. For a list over the notation used in this manual, see Section \@ref(notation). Let $\mu$ be the effect estimated from data of interest, which can includes mean difference, risk ratio (relative risk), odds ratio or risk difference. We often wish to compare the effect estimated to a value described by the null hypothesis, we define this value to be $\mu_0$. For mean differences $\mu_0$ is often 0, while for risk and odds ratios the value is 1. 

### Two sided testing

In the two-tailed or two sided test, we specify our null and alternative hypothesis as: 

$$H_0: \mu = \mu_0 $$ against
$$H_A: \mu \neq \mu_0 $$
An example of a two sided test, is the test of which of two treatments is better. We will provide a few examples of real-world applications tested using two-sided tests. 

ONE FIGURE HERE, TWO SIDED TESTING

#### Continuous outcome

Maybe an example here

#### Binary outcome

Maybe an example here

### One sided testing

In the one-tailed or one sided test, we specify our null and alternative hypothesis as: 

$$H_0: \mu \leq \mu_0 $$ against
$$H_A: \mu > \mu_0.$$

An example of a one sided test is the test of whether a new treatment is more effective than placebo. It is common in group sequential methods to also test futility, when interested in one-sided hypothesis testing.

TWO FIGURES HERE: ONE OF ONE-SIDED TEST WITH AND ONE WITHOUT FUTILITY BOUNDARIES

### Futility testing

If there is sufficient statistical evidence against the alternative hypothesis, it might be just as beneficial to stop the meta-analysis early for futility as it would have been to stop it for benefit or harm. Futility testing can provide information about how unlikely it is to reject the null hypothesis and allow for an early stopping, hence one can finish the meta-analysis without having reached the required sample size. Futility testing can be used in combination with the two or one sided hypothesis testing or stand alone. When stand alone, the futility testing can be used as a equivalence test. 

We will consider two kinds of futility in TSA, binding and non-binding futility. When binding futility is considered, we assume that the meta-analysis will be stopped. When non-binding futility is chosen, the futility boundaries should only be used as a visual aid, and should not be used to make a decision to stop the meta-analysis. 

Futility hypothesis testing in TSA is created using $\beta$ spending functions, a topic we will address in a later section. 

TWO FIGURES HERE: ONE SIDED FUTILITY, TWO SIDED FUTILITY

## Type I and type II error

Consider a scenario where we wish to reject the null hypothesis $H_0: \theta = 0$, where the alternative hypothesis is $H_A: \theta \neq 0$. The parameter $\theta$ is used, when we are interested in a treatment difference. As the alternative allows for both $\theta > 0$, intervention being superior, and $\theta < 0$, intervention being inferior, it is a two-sided test, we are considering.

State something about $\theta$ being normally distributed.

Considering the test statistic $Z$, we have that $$P_{\theta = 0}(\vert Z\vert > c) = \alpha$$

Here $\alpha$ is the type-1-error, the probability of a false positive.

$$P_{\theta = \delta}(\vert Z \vert > c) = P_{\theta = -\delta}(\vert Z \vert > c) = 1 - \beta$$ Here $\beta$ is the type-2-error, the probability of a false negative. Power is then defined as: $1-\beta$.


## Heterogeneity, $\tau^2$, estimation 

When using a random-effects model, we are estimating a between-study variation, often denoted by $\tau^2$. The random-effects meta-analysis assumes that the studies do not share one true parameter $\theta$. Instead it is assumed that each study has its own true parameter $\theta_i$, where the $\theta_i$ follow a normal distribution with a location parameter $\theta$ and variance parameter $\tau^2$.

There are different methods to calculate the estimate of the heterogeneity, $\tau^2$. We use one of the methods based on the $Q$ statistic calculated by, 
$$Q = \sum_{i = 1}^k w_i \cdot (y_i - \hat{\mu})^2.$$
The weights $w_i$ are the inverse-variance weights. Other methods use other choices of weights for the calculation of $Q$. For more information about the $Q$ statistic see [@Borenstein2009] and [@jackson2016]. 

There are several other methods for estimating the $\tau^2$ parameter. For more choices, we recommend using either the `meta` package or the `metafor` package.  

### DerSimonian-Laird

### Hartung-Knapp-Sidik-Jonkman adjustment

### REML

For continuous outcomes, one can consider REML estimation of the heterogeneity $\tau^2$. 

### Confidence intervals of $\tau^2$

Using the `metafor` package, we provide two different kinds of confidence interval methods for $\tau^2$. These methods are: The Q Profile (QP) method and Biggerstaff and Jackson (BJ) method. These methods has been recommended by @veroniki2015. In their paper, it is recommended to use QP method for large $\tau^2$ and the BJ method for smaller $\tau^2$. Given the results in @jackson2013, large $\tau^2$ is around 0.2. For more choices of confidence intervals, we recommend using either the `meta` package or the `metafor` package.  

# Practical implementations

To ensure an as smooth 

## Handling of zero-trials

In a situation with binary data as outcome data, there might be studies where no events were observed for either both or one of the treatment groups. When both treatment groups have no events, we call these studies total-zero-studies. 

When the effect estimates from the studies are represented as risk ratios/relative risks (RR) or odds ratios (OR)

## Adding small trials to the meta-analysis

## 




# Reliability and quality control

To ensure the correctness and quality of the code in RTSA, we will be comparing the output of RTSA to other packages. Unfortunately, no package in R offer sequential stopping boundaries for meta-analysis. This is one of the reasons for creating the *RTSA*-package. For this reason we will both be comparing results from *RTSA* with the original [TSA-software](https://ctu.dk/tsa/) coded in Java (TSA v. **XXXXX**, Copenhagen Trial Unit, Copenhagen, Denmark) and to packages available on CRAN. The intended use of the packages available on CRAN is not for sequential meta-analysis, but the mathematical algorithms are comparable.

TSA requires a traditional meta-analysis which have been implemented as part for the *RTSA*-package. As the *RTSA*-package is not created mainly for this purpose, we recommend using the [*metafor*](https://cran.r-project.org/web/packages/metafor/index.html)-package in R for traditional meta-analysis as this package has an extensive selection of methods and documentation. We will compare the results of the *RTSA*-package and the [*metafor*](https://cran.r-project.org/web/packages/metafor/index.html)-package for the traditional meta-analysis.

The methods for calculating the sequential stopping boundaries in TSA are almost identical to the methods for calculating sequential stopping boundaries in clinical trials. Hence we can compare the *RTSA*-package with the existing packages in R for calculating stopping boundaries. We will specifically be comparing our stopping boundaries to the [*gsDesign*](https://cran.r-project.org/web/packages/gsDesign/gsDesign.pdf)-package. The [*gsDesign*](https://cran.r-project.org/web/packages/gsDesign/gsDesign.pdf)- and *RTSA*-packages differ in their intended purpose. The [*gsDesign*](https://cran.r-project.org/web/packages/gsDesign/gsDesign.pdf)-package is created for sequential methods in clinical trials and the *RTSA*-package is created for sequential methods in meta-analysis. Even with their difference in indended use, the boundries should be comparable.

For investigation of reliability we will use the `perioOxy`-data included in the *RTSA*-package.

```{r}
data("perioOxy")
head(perioOxy)
```

## Traditional meta-analysis

In the *RTSA*-package, we will be using the functions `metaPrepare` and `synthesize` to create a traditional meta-analysis. The function `metaPrepare` uses binary summary data (events and number of participants) as input and returns a list of trial specific treatment effects, confidence intervals and more.

```{r}
mp <- RTSA:::metaPrepare(outcome = "RR", eI = perioOxy$eI, nI = perioOxy$nI,
                 eC = perioOxy$eC, nC = perioOxy$nC, method = "IV")
```

The `escalc`-function in the [*metafor*](https://cran.r-project.org/web/packages/metafor/index.html)-package does essentially the same as the `metaPrepare`-function. To compute confidence intervals per trial, the summary function can be used. The results from the escalc function can be seen in Table \@ref(tab:trameta).

```{r}
me <- metafor::escalc(measure="RR", n1i=nI, n2i=nC, ai=eI, ci=eC, data=perioOxy)
sum.me <- summary(me)
```

```{r trameta, echo = FALSE}
out.mat <- cbind(perioOxy$study, round(mp$te, 2), paste0("(", round(mp$lower,2), "; ", round(mp$upper,2),")"), round(exp(me$yi),2), paste0("(", round(exp(sum.me$ci.lb),2), "; ", round(exp(sum.me$ci.ub),2),")"))
colnames(out.mat) <- c("Trial", "Effect estimate ", "95% CI", "Effect estimate ", "95% CI")
knitr::kable(out.mat, caption = "Results from the metaPrepare and escalc function") %>% kable_paper() %>% add_header_above(c("", "RTSA::metaPrepare" = 2, "metafor::escalc and summary" = 2))
```

The saved object from `metaPrepare` can be used to compute a traditional meta-analysis by the function `synthesize` in *RTSA*-package. The `synthesize`-function returns a list containing information about a fixed-effect meta-analysis, a random-effects meta-analysis and more. We will specifically be fitting a fixed-effect model (always fitted) and a random-effects model (fitted per default) using the DerSimonian-Laird estimator for the heterogeneity. We will be comparing the output of the synthesize function with the `rma`-function from the [*metafor*](https://cran.r-project.org/web/packages/metafor/index.html)-package. See Table \@ref(tab:trametaout).

```{r}
sm <- RTSA:::synthesize(mp) # RTSA function
out.mtFE <- metafor::rma(yi, vi, data = me, method = "FE") # metafor function
out.mtRE <- metafor::rma(yi, vi, data = me, method = "DL") # metafor function
```

```{r trametaout, echo = FALSE}
out.mat <- rbind(c(round(sm$peF[c(1,2,3)],2),round(sm$peF[5],4),
                  c(round(exp(c(out.mtFE$beta, out.mtFE$ci.lb, out.mtFE$ci.ub)),2),
                    round(out.mtFE$pval,4))),
                c(round(sm$peR[c(1,2,3)],2),round(sm$peR[5],4),
                  round(exp(c(out.mtRE$beta, out.mtRE$ci.lb, out.mtRE$ci.ub)),2),
                  round(out.mtRE$pval,4)))
out.mat[,c(2,6)] <- c(paste0("(", out.mat[,2], "; ", out.mat[,3],")"),
                    paste0("(", out.mat[,6], "; ", out.mat[,7],")"))
out.mat = out.mat[,-c(3,7)]
colnames(out.mat) <- c("Effect estimate ", "95% CI", "p-value", "Effect estimate ",
                      "95% CI", "p-value")
rownames(out.mat) <- c("Fixed-effect", "Random-effects")
knitr::kable(out.mat, caption = "Results from the synthesize and rma function") %>% kable_paper() %>% add_header_above(c("", "RTSA::synthesize" = 3, "metafor::rma" = 3))
```

## Sequential meta-analysis

The RTSA package is mainly created for sequential meta-analysis. We will first focus on the boundary calculation before looking at the main RTSA function in our package.

```{r}
# Calculate the cumulative number of participants
count <- cumsum(perioOxy$nI+perioOxy$nC)

# Calculate the RIS 
RR = 0.9
p0 = sum(perioOxy$eC+perioOxy$eI)/sum(perioOxy$nC+perioOxy$nI)
pI = exp(log(p0)+log(RR))
pC = exp(log(p0)-log(RR))
RIS = RTSA:::nRandom(alpha = 0.05, beta = 0.2, pI = pI, pC = pC, diversity = 0.2)

# Set the timings of the studies relative to the RIS
timing <- c(count/RIS,1)

# create increment in the information
timingincr <- timing - c(0,timing[-length(timing)])
trials <- cbind(timing, timingincr, c(count,RIS))

# Start BoundaryCalculations programme ------------------------------------
# do not analyse after too small an increment in information
IFincrementThreshold <- 0.01
IFtotalThreshold <- 0.05

trials <- trials[trials[,2] > IFincrementThreshold,]

# calculate the boundaries
boundaries <- RTSA:::boundary(informationFractions = trials[,1],
                 side = 1, alpha = 0.05, zninf = -8, tol = 1e-24)
boundaries
```

We can compare our boundaries to the gsDesign package.

```{r}
library(gsDesign)
gs = gsDesign(k = 7,
         n.I = trials[,3],
         test.type = 1,
         alpha = 0.05, sfu = sfLDOF, sfl = sfLDOF)
gs$upper$bound
```

## Continuous outcome

Testing cont. outcome

```{r}
data("perioOxy")
perioOxy[c(4,5),c(3,5)] <- 0
#names(perioOxy)[1] <- "Col1"
metaanalysis(outcome = "RR", data = perioOxy, 
             method = "MH")
```

# Notation

-   $\alpha$: Proportion of false positives, also called type-1-error.
-   $H_0$: Null-hypothesis
-   $H_A$: Alternative hypothesis
-   $\mu$: Location parameter in the normal distribution
-   $\theta$: Effect of treatment between two populations represented by mean difference, relative risk etc.

# References
